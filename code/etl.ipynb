{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "MED_FILE = \"PRESCRIPTIONS.csv\"\n",
    "DIAGS_FILE = \"DIAGNOSES_ICD.csv\"\n",
    "NDC_TO_ADC_FILE = \"package_NDC_ATC4_classes.csv\"\n",
    "PROCEDURE_FILE = \"PROCEDURES_ICD.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_med():\n",
    "    Field = [\"SUBJECT_ID\",\"HADM_ID\",\"ICUSTAY_ID\",\"STARTDATE\",\"NDC\"]\n",
    "    FieldType = {\"SUBJECT_ID\": 'Int64',\n",
    "                \"HADM_ID\": 'Int64',\n",
    "                \"ICUSTAY_ID\": 'Int64',\n",
    "                \"NDC\": 'str',\n",
    "                }\n",
    "    med_df = pd.read_csv(DATA_PATH+MED_FILE, usecols=Field, dtype=FieldType, parse_dates=[\"STARTDATE\"])\n",
    "\n",
    "    med_df = med_df[med_df['NDC'] != '0'] \n",
    "    med_df.fillna(method='pad', inplace=True)\n",
    "    med_df.dropna(inplace=True) \n",
    "    med_df.drop_duplicates(inplace=True)\n",
    "    med_df.sort_values(by=['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'STARTDATE'], inplace=True)\n",
    "    med_df = med_df.reset_index(drop=True)\n",
    "\n",
    "    def filter_first24hour_med(med_df):\n",
    "        med_df_new = med_df.drop(columns=['NDC'])\n",
    "        med_df_new = med_df_new.groupby(by=['SUBJECT_ID','HADM_ID','ICUSTAY_ID']).head(1).reset_index(drop=True) #returns the first startdate\n",
    "        med_df_new = pd.merge(med_df_new, med_df, on=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','STARTDATE'])\n",
    "        med_df_new = med_df_new.drop(columns=['STARTDATE'])\n",
    "        return med_df_new\n",
    "    med_df = filter_first24hour_med(med_df) \n",
    "    med_df = med_df.drop(columns=['ICUSTAY_ID'])\n",
    "    med_df = med_df.drop_duplicates()\n",
    "\n",
    "    return med_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ndc2atc4():\n",
    "    \"\"\" process_ndc2atc4 reformats ndc from 10 digits to 11 digits \n",
    "            https://www.michigan.gov/-/media/Project/Websites/lara/healthsystemslicensing/Folder4/lara_MAPS_NDC_Guidelines.pdf?rev=4cb0e4c8d98946659f47dce703dabc22\n",
    "\n",
    "        return: 2 column array ['NDC','ATC_class']\n",
    "    \"\"\"\n",
    "    Field = [\"NDC\",\"ATC_class\"]\n",
    "    FieldType = {\"NDC\": 'str',\n",
    "                \"ATC_class\": 'str'\n",
    "                }\n",
    "    ndc2atc_df = pd.read_csv(DATA_PATH+NDC_TO_ADC_FILE, usecols=Field, dtype=FieldType)\n",
    "    ndc2atc_df[['Seg1', 'Seg2', 'Seg3']] = ndc2atc_df['NDC'].str.split('-', expand=True)\n",
    "    ndc2atc_df['Seg1'] = ndc2atc_df['Seg1'].str.pad(side=\"left\",width=5,fillchar='0')\n",
    "    ndc2atc_df['Seg2'] = ndc2atc_df['Seg2'].str.pad(side=\"left\",width=4,fillchar='0')\n",
    "    ndc2atc_df['Seg3'] = ndc2atc_df['Seg3'].str.pad(side=\"left\",width=2,fillchar='0')\n",
    "    ndc2atc_df['NDC'] = ndc2atc_df[['Seg1', 'Seg2', 'Seg3']].agg(''.join, axis=1)\n",
    "    ndc2atc_df = ndc2atc_df.drop_duplicates()\n",
    "    return ndc2atc_df.filter(items=['NDC','ATC_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndc2atc4(med_pd):\n",
    "    with open('../data/ndc2rxnorm_mapping.txt', 'r') as f:\n",
    "        ndc2rxnorm = eval(f.read())\n",
    "    med_pd['RXCUI'] = med_pd['NDC'].map(ndc2rxnorm)\n",
    "    med_pd.dropna(inplace=True)\n",
    "\n",
    "    rxnorm2atc = pd.read_csv('../data/ndc2atc_level4.csv')\n",
    "    rxnorm2atc = rxnorm2atc.drop(columns=['YEAR', 'MONTH', 'NDC'])\n",
    "    rxnorm2atc.drop_duplicates(subset=['RXCUI'], inplace=True)\n",
    "    med_pd.drop(index=med_pd[med_pd['RXCUI'].isin(\n",
    "        [''])].index, axis=0, inplace=True)\n",
    "\n",
    "    med_pd['RXCUI'] = med_pd['RXCUI'].astype('int64')\n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    med_pd = med_pd.merge(rxnorm2atc, on=['RXCUI'])\n",
    "    med_pd.drop(columns=['NDC', 'RXCUI'], inplace=True)\n",
    "    \n",
    "    med_pd['ATC4'] = med_pd['ATC4'].map(lambda x: x[:5])\n",
    "    med_pd = med_pd.drop_duplicates()\n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    med_pd.rename(columns={'ATC4': 'ATC_class'}, inplace=True)\n",
    "    return med_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakeh\\AppData\\Local\\Temp\\ipykernel_13056\\3121096391.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  med_df.fillna(method='pad', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "med_df = process_med()\n",
    "ndc2atc_df = process_ndc2atc4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337186, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndc2atc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "med_df['NDC'].unique()\n",
    "\n",
    "np.savetxt(str(DATA_PATH)+\"input.txt\", med_df['NDC'].unique(), fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID     Int64\n",
       "HADM_ID        Int64\n",
       "NDC           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['63323017302', '63323038810', '00088222033', ..., '00904125061',\n",
       "       '11980002205', '00075800180'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_df['NDC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898277, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = med_df.merge(ndc2atc_df, right_on='NDC',left_on='NDC', how='left')\n",
    "test = test.drop_duplicates()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diag():\n",
    "    diag_df = pd.read_csv(DATA_PATH+DIAGS_FILE)\n",
    "    diag_df = diag_df.dropna()\n",
    "    diag_df = diag_df.drop(columns=['SEQ_NUM','ROW_ID'])\n",
    "    diag_df = diag_df.drop_duplicates()\n",
    "    diag_df = diag_df.sort_values(by=['SUBJECT_ID', 'HADM_ID']).reset_index(drop=True)\n",
    "    return diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did num = 129 instead of 128 to make the shapes match the output of their code since our\n",
    "# filtering methods are different.\n",
    "\n",
    "def filter_diag(diag_df, num=129):\n",
    "    most_common_codes = diag_df['ICD9_CODE'].value_counts().head(num).index\n",
    "    diag_df = diag_df[diag_df['ICD9_CODE'].isin(most_common_codes)].reset_index(drop=True)\n",
    "    return diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_df = process_diag()\n",
    "# print(diag_df.shape)\n",
    "\n",
    "diag_df = filter_diag(diag_df)\n",
    "# print(diag_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_visit(med_df,single_visit):\n",
    "    grouped_med_patients = med_df[['SUBJECT_ID', 'HADM_ID']].groupby(['SUBJECT_ID'])['HADM_ID'].unique().reset_index()\n",
    "    grouped_med_patients['length'] = grouped_med_patients['HADM_ID'].apply(lambda x: len(x))\n",
    "    if single_visit:\n",
    "        grouped_med_patients = grouped_med_patients[grouped_med_patients['length'] == 1].reset_index(drop=True)\n",
    "    else:\n",
    "        grouped_med_patients = grouped_med_patients[grouped_med_patients['length'] > 1].reset_index(drop=True)\n",
    "    df = med_df[med_df['SUBJECT_ID'].isin(grouped_med_patients['SUBJECT_ID'].unique())].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def filter_patients(df):\n",
    "    drop_subjects = []\n",
    "    for subject in df['SUBJECT_ID'].unique():\n",
    "        subject_data = df[df['SUBJECT_ID'] == subject]\n",
    "        for index, row in subject_data.iterrows():\n",
    "            if len(list(row['ICD9_CODE'])) < 2 and len(list(row['ATC_class'])) < 2:\n",
    "                drop_subjects.append(subject)\n",
    "                break\n",
    "    return df[~df['SUBJECT_ID'].isin(drop_subjects)].reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pro():\n",
    "    pro_df = pd.read_csv(DATA_PATH+PROCEDURE_FILE, dtype={'ICD9_CODE': 'category'})\n",
    "    pro_df = pro_df.drop(columns=['ROW_ID'])\n",
    "    pro_df = pro_df.drop_duplicates()\n",
    "    pro_df = pro_df.sort_values(by=['SUBJECT_ID', 'HADM_ID']).reset_index(drop=True)\n",
    "    pro_df = pro_df.drop(columns=['SEQ_NUM'])\n",
    "    pro_df = pro_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return pro_df\n",
    "\n",
    "\n",
    "def process_all(single_visit):\n",
    "    med_df = process_med()\n",
    "    # print(\"med_df shape\", med_df.shape)\n",
    "    med_df = ndc2atc4(med_df)\n",
    "    # med_df = med_df.merge(ndc_atc_mapping, on='NDC', how='left')\n",
    "    # print(med_df.shape)\n",
    "    med_df = filter_by_visit(med_df,single_visit)\n",
    "    diag_df = process_diag()\n",
    "    # print(\"diag_df shape\", diag_df.shape)\n",
    "    diag_df = filter_diag(diag_df,num=2000)\n",
    "    # print(\"diag_df shape\", diag_df.shape)\n",
    "\n",
    "    if single_visit:\n",
    "\n",
    "        # print(\"med\", med_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().shape)\n",
    "        # print(\"diag\", diag_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().shape)\n",
    "        keys = [set(map(tuple, med_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().values)),\n",
    "                set(map(tuple, diag_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().values))]\n",
    "        \n",
    "        common_keys = set.intersection(*keys)\n",
    "        # print('common_keys', len(common_keys))\n",
    "        common_df = pd.DataFrame(list(common_keys), columns=['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "        med_df = med_df.merge(common_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "        # print('med_df shape', med_df.shape)\n",
    "        diag_df = diag_df.merge(common_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "        # print('diag_df shape', diag_df.shape)\n",
    "\n",
    "        med_df = med_df.groupby(['SUBJECT_ID', 'HADM_ID'])['ATC_class'].unique().reset_index()\n",
    "        diag_df = diag_df.groupby(['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].unique().reset_index()\n",
    "\n",
    "        med_df['ATC_class'] = med_df['ATC_class'].apply(lambda x: list(x))\n",
    "        diag_df['ICD9_CODE'] = diag_df['ICD9_CODE'].apply(lambda x: list(x))\n",
    "\n",
    "        df = med_df.merge(diag_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "\n",
    "    else:\n",
    "        pro_df = process_pro()\n",
    "        keys = [set(map(tuple, med_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().values)),\n",
    "                set(map(tuple, diag_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().values)),\n",
    "                set(map(tuple, pro_df[['SUBJECT_ID', 'HADM_ID']].drop_duplicates().values))]\n",
    "        \n",
    "        common_keys = set.intersection(*keys)\n",
    "        common_df = pd.DataFrame(list(common_keys), columns=['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "        med_df = med_df.merge(common_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "        diag_df = diag_df.merge(common_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "        pro_df = pro_df.merge(common_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "\n",
    "        med_df = med_df.groupby(['SUBJECT_ID', 'HADM_ID'])['ATC_class'].unique().reset_index()\n",
    "        diag_df = diag_df.groupby(['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].unique().reset_index()\n",
    "        pro_df = pro_df.groupby(['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].unique().reset_index().rename(columns={'ICD9_CODE': 'PRO_CODE'})\n",
    "\n",
    "        med_df['ATC_class'] = med_df['ATC_class'].apply(lambda x: list(x))\n",
    "        diag_df['ICD9_CODE'] = diag_df['ICD9_CODE'].apply(lambda x: list(x))\n",
    "        pro_df['PRO_CODE'] = pro_df['PRO_CODE'].apply(lambda x: list(x))\n",
    "\n",
    "        df = med_df.merge(diag_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "        df = df.merge(pro_df, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    \n",
    "    # print(df.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "def run(single_visit):\n",
    "    df = process_all(single_visit)\n",
    "    # print(df.shape)\n",
    "    df = filter_patients(df)\n",
    "\n",
    "    med = df['ICD9_CODE'].values\n",
    "    diag = df['ATC_class'].values\n",
    "\n",
    "    med_unique = set([j for i in med for j in list(i)])\n",
    "    diag_unique = set([j for i in diag for j in list(i)])\n",
    "\n",
    "    return df, med_unique, diag_unique    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakeh\\AppData\\Local\\Temp\\ipykernel_13056\\3121096391.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  med_df.fillna(method='pad', inplace=True)\n",
      "C:\\Users\\jakeh\\AppData\\Local\\Temp\\ipykernel_13056\\3121096391.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  med_df.fillna(method='pad', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_single_visit, med1, diag1 = run(single_visit=True)\n",
    "data_multi_visit, med2, diag2 = run(single_visit=False)\n",
    "\n",
    "unique_diag = set.union(med1, med2)\n",
    "unique_med = set.union(diag1, diag2)\n",
    "\n",
    "with open('../model_data/unique_diags.txt', 'w') as f:\n",
    "    for item in unique_diag:\n",
    "        f.write(str(item) + '\\n')\n",
    "\n",
    "with open('../model_data/unique_meds.txt', 'w') as f:\n",
    "    for item in unique_med:\n",
    "        f.write(str(item) + '\\n')\n",
    "\n",
    "with open('../model_data/multi-visit-diags.txt', 'w') as f:\n",
    "    for item in diag2:\n",
    "        f.write(str(item) + '\\n')\n",
    "\n",
    "with open('../model_data/multi-visit-meds.txt', 'w') as f:\n",
    "    for item in med2:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_single_visit.shape, data_multi_visit.shape)\n",
    "# print(data_single_visit.columns)\n",
    "# print(data_multi_visit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "subject_ids = data_multi_visit['SUBJECT_ID'].unique()\n",
    "\n",
    "train_ids, temp_ids = train_test_split(subject_ids, test_size=1/3, random_state=1203)\n",
    "\n",
    "eval_ids, test_ids = train_test_split(temp_ids, test_size=1/2, random_state=1203)\n",
    "\n",
    "with open('../model_data/train-id.txt', 'w') as f:\n",
    "    for item in train_ids:\n",
    "        f.write(str(item) + '\\n')\n",
    "\n",
    "with open('../model_data/eval-id.txt', 'w') as f:\n",
    "    for item in eval_ids:\n",
    "        f.write(str(item) + '\\n')\n",
    "\n",
    "with open('../model_data/test-id.txt', 'w') as f:\n",
    "    for item in test_ids:\n",
    "        f.write(str(item) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBERT_BD4H",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
